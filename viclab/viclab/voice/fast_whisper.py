import queue
import threading
import pyaudio
import numpy as np
from faster_whisper import WhisperModel

# é…ç½®æ¨¡å‹
model = WhisperModel("small", compute_type="int8")  # æ”¯æŒ tiny, base, small, medium, large

# éŸ³é¢‘è®¾ç½®
RATE = 16000
CHUNK = 1024  # æ¯æ¬¡è¯»å–çš„éŸ³é¢‘å¸§æ•°
CHANNELS = 1
FORMAT = pyaudio.paInt16

audio_queue = queue.Queue()

# éº¦å…‹é£å½•éŸ³çº¿ç¨‹
def record_audio():
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    print("ğŸ¤ å¼€å§‹ç›‘å¬éº¦å…‹é£... æŒ‰ Ctrl+C é€€å‡º")
    try:
        while True:
            data = stream.read(CHUNK)
            audio_queue.put(data)
    except KeyboardInterrupt:
        print("ğŸ›‘ åœæ­¢å½•éŸ³")
        stream.stop_stream()
        stream.close()
        p.terminate()

# æ¨ç†çº¿ç¨‹
def transcribe_streaming():
    buffer = b""
    sample_limit = RATE * 5  # æ¯ 5 ç§’è·‘ä¸€æ¬¡æ¨ç†
    frame_count = 0

    while True:
        data = audio_queue.get()
        buffer += data
        frame_count += len(data)

        if frame_count >= sample_limit * 2:  # int16 æ¯ä¸ªæ ·æœ¬2å­—èŠ‚
            # è½¬æ¢ä¸º float32
            audio_np = np.frombuffer(buffer, np.int16).astype(np.float32) / 32768.0

            segments, _ = model.transcribe(audio_np, language="zh", beam_size=5)
            for seg in segments:
                print(f"[{seg.start:.2f}s - {seg.end:.2f}s]: {seg.text}")

            buffer = b""
            frame_count = 0

# å¯åŠ¨ä¸¤ä¸ªçº¿ç¨‹
recording_thread = threading.Thread(target=record_audio)
transcription_thread = threading.Thread(target=transcribe_streaming)

recording_thread.start()
transcription_thread.start()
